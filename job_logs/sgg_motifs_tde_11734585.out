[32m2023-12-14 11:39:23.304[0m | [1mINFO    [0m | [36msgg_benchmark.utils.logger[0m:[36msetup_logger[0m:[36m30[0m - [1mUsing loguru logger with level: INFO[0m
[32m2023-12-14 11:39:23.309[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m416[0m - [1mUsing 2 GPUs[0m
[32m2023-12-14 11:39:23.309[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m419[0m - [1mCollecting environment info...[0m
[32m2023-12-14 11:39:34.831[0m | [1mINFO    [0m | [36msgg_benchmark.utils.logger[0m:[36mlogger_step[0m:[36m15[0m - [1m#################### Step 1: 
PyTorch version: 1.13.1+cu117
Is debug build: False
CUDA used to build PyTorch: 11.7
ROCM used to build PyTorch: N/A

OS: Red Hat Enterprise Linux release 8.6 (Ootpa) (x86_64)
GCC version: (GCC) 8.5.0 20210514 (Red Hat 8.5.0-10)
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.28

Python version: 3.10.13 | packaged by conda-forge | (main, Oct 26 2023, 18:07:37) [GCC 12.3.0] (64-bit runtime)
Python platform: Linux-4.18.0-372.75.1.el8_6.x86_64-x86_64-with-glibc2.28
Is CUDA available: True
CUDA runtime version: 11.7.99
CUDA_MODULE_LOADING set to: LAZY
GPU models and configuration: 
GPU 0: Tesla V100-SXM2-32GB
GPU 1: Tesla V100-SXM2-32GB

Nvidia driver version: 535.129.03
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

Versions of relevant libraries:
[pip3] numpy==1.26.2
[pip3] torch==1.13.1+cu117
[pip3] torchaudio==0.13.1+cu117
[pip3] torchtext==0.4.0
[pip3] torchvision==0.14.1+cu117
[conda] cudatoolkit               11.7.1              h4bc3d14_12    conda-forge
[conda] cudatoolkit-dev           11.7.0               h1de0b5d_6    conda-forge
[conda] numpy                     1.26.2                   pypi_0    pypi
[conda] torch                     1.13.1+cu117             pypi_0    pypi
[conda] torchaudio                0.13.1+cu117             pypi_0    pypi
[conda] torchtext                 0.4.0                    pypi_0    pypi
[conda] torchvision               0.14.1+cu117             pypi_0    pypi
        Pillow (10.1.0) ####################[0m
[32m2023-12-14 11:39:34.831[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m422[0m - [1mLoaded configuration file configs/VG178/e2e_relation_X_101_32_8_FPN_1x.yaml[0m
[32m2023-12-14 11:39:34.832[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m426[0m - [1mRunning with config:
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 4
  SIZE_DIVISIBILITY: 32
DATASETS:
  NAME: 
  TEST: ('VG178_test',)
  TO_TEST: 
  TRAIN: ('VG178_train',)
  VAL: ('VG178_val',)
DETECTED_SGG_DIR: .
DTYPE: float16
GLOVE_DIR: /gpfswork/rech/gtb/ukj95zg/glove
INPUT:
  BRIGHTNESS: 0.0
  CONTRAST: 0.0
  HUE: 0.0
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  SATURATION: 0.0
  TO_BGR255: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
METRIC_TO_TRACK: mR
MODEL:
  ATTRIBUTE_ON: False
  BACKBONE:
    CONV_BODY: R-101-FPN
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FLIP_AUG: False
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PRETRAINED_DETECTOR_CKPT: /gpfswork/rech/gtb/ukj95zg/Scene-Graph-Benchmark-Cuda11.7/checkpoints/faster_rcnn/best_model_0058000.pth
  RELATION_ON: True
  RESNETS:
    BACKBONE_OUT_CHANNELS: 256
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 32
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 8
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_ATTRIBUTE_HEAD:
    ATTRIBUTE_BGFG_RATIO: 3
    ATTRIBUTE_BGFG_SAMPLE: True
    ATTRIBUTE_LOSS_WEIGHT: 1.0
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MAX_ATTRIBUTES: 10
    NUM_ATTRIBUTES: 201
    POS_WEIGHT: 50.0
    PREDICTOR: FPNPredictor
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_BINARY_LOSS: True
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 4096
    NUM_CLASSES: 179
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.3
    DETECTIONS_PER_IMG: 50
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.3
    NMS_FILTER_DUPLICATES: True
    POSITIVE_FRACTION: 0.5
    POST_NMS_PER_CLS_TOPN: 300
    SCORE_THRESH: 0.01
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  ROI_RELATION_HEAD:
    ADD_GTBOX_TO_PROPOSAL_IN_TRAIN: True
    BATCH_SIZE_PER_IMAGE: 1024
    CAUSAL:
      CONTEXT_LAYER: motifs
      EFFECT_ANALYSIS: True
      EFFECT_TYPE: TDE
      FUSION_TYPE: sum
      SEPARATE_SPATIAL: False
      SPATIAL_FOR_VISION: True
    CONTEXT_DROPOUT_RATE: 0.2
    CONTEXT_HIDDEN_DIM: 512
    CONTEXT_OBJ_LAYER: 1
    CONTEXT_POOLING_DIM: 4096
    CONTEXT_REL_LAYER: 1
    EMBED_DIM: 200
    FEATURE_EXTRACTOR: RelationFeatureExtractor
    LABEL_SMOOTHING_LOSS: False
    NUM_CLASSES: 46
    NUM_SAMPLE_PER_GT_REL: 4
    POOLING_ALL_LEVELS: True
    POSITIVE_FRACTION: 0.25
    PREDICTOR: CausalAnalysisPredictor
    PREDICT_USE_BIAS: True
    PREDICT_USE_VISION: True
    REL_PROP: [0.01858, 0.00057, 0.00051, 0.00109, 0.0015, 0.00489, 0.00432, 0.02913, 0.00245, 0.00121, 0.00404, 0.0011, 0.00132, 0.00172, 5e-05, 0.00242, 0.0005, 0.00048, 0.00208, 0.15608, 0.0265, 0.06091, 0.009, 0.00183, 0.00225, 0.0009, 0.00028, 0.00077, 0.04844, 0.08645, 0.31621, 0.00088, 0.00301, 0.00042, 0.00186, 0.001, 0.00027, 0.01012, 0.0001, 0.01286, 0.00647, 0.00084, 0.01077, 0.00132, 0.00069, 0.00376, 0.00214, 0.11424, 0.01205, 0.02958]
    REQUIRE_BOX_OVERLAP: False
    TRANSFORMER:
      DROPOUT_RATE: 0.1
      INNER_DIM: 2048
      KEY_DIM: 64
      NUM_HEAD: 8
      OBJ_LAYER: 4
      REL_LAYER: 2
      VAL_DIM: 64
    USE_GT_BOX: False
    USE_GT_OBJECT_LABEL: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.23232838, 0.63365731, 1.28478321, 3.15089189)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 1000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 1000
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    RPN_MID_CHANNEL: 256
    STRADDLE_THRESH: 0
    USE_FPN: True
  RPN_ONLY: False
  VGG:
    VGG16_OUT_CHANNELS: 512
  WEIGHT: catalog://ImageNetPretrained/FAIR/20171220/X-101-32x8d
OUTPUT_DIR: /gpfswork/rech/gtb/ukj95zg/Scene-Graph-Benchmark-Cuda11.7/checkpoints/VG178
PATHS_CATALOG: /gpfsdswork/projects/rech/gtb/ukj95zg/Scene-Graph-Benchmark-Cuda11.7/sgg_benchmark/config/paths_catalog.py
PATHS_DATA: /home/maelic/Documents/Datasets/VG/
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1
  CHECKPOINT_PERIOD: 4000
  CLIP_NORM: 5.0
  GAMMA: 0.1
  GRAD_NORM_CLIP: 5.0
  IMS_PER_BATCH: 12
  MAX_ITER: 50000
  MOMENTUM: 0.9
  PRE_VAL: False
  PRINT_GRAD_FREQ: 4000
  SCHEDULE:
    COOLDOWN: 0
    FACTOR: 0.1
    MAX_DECAY_STEP: 3
    PATIENCE: 2
    THRESHOLD: 0.001
    TYPE: WarmupReduceLROnPlateau
  STEPS: (10000, 16000)
  TO_VAL: True
  UPDATE_SCHEDULE_DURING_LOAD: False
  VAL_PERIOD: 2000
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0
TEST:
  ALLOW_LOAD_FROM_CACHE: False
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  CUSTUM_EVAL: False
  CUSTUM_PATH: .
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 2
  RELATION:
    IOU_THRESHOLD: 0.5
    LATER_NMS_PREDICTION_THRES: 0.5
    MULTIPLE_PREDS: False
    REQUIRE_OVERLAP: False
    SYNC_GATHER: True
  SAVE_PROPOSALS: False[0m
[32m2023-12-14 11:39:34.842[0m | [1mINFO    [0m | [36m__main__[0m:[36mmain[0m:[36m429[0m - [1mSaving config into: /gpfswork/rech/gtb/ukj95zg/Scene-Graph-Benchmark-Cuda11.7/checkpoints/VG178/config.yml[0m
[32m2023-12-14 11:39:34.888[0m | [1mINFO    [0m | [36msgg_benchmark.utils.logger[0m:[36mlogger_step[0m:[36m15[0m - [1m#################### Step 2: Building model... ####################[0m
[32m2023-12-14 11:39:39.860[0m | [1mINFO    [0m | [36msgg_benchmark.data.build[0m:[36mget_dataset_statistics[0m:[36m30[0m - [1m----------------------------------------------------------------------------------------------------[0m
[32m2023-12-14 11:39:39.860[0m | [1mINFO    [0m | [36msgg_benchmark.data.build[0m:[36mget_dataset_statistics[0m:[36m31[0m - [1mget dataset statistics...[0m
[32m2023-12-14 11:39:39.869[0m | [1mINFO    [0m | [36msgg_benchmark.data.build[0m:[36mget_dataset_statistics[0m:[36m42[0m - [1mLoading data statistics from: /gpfswork/rech/gtb/ukj95zg/Scene-Graph-Benchmark-Cuda11.7/checkpoints/VG178/VG178_train_statistics.cache[0m
[32m2023-12-14 11:39:39.869[0m | [1mINFO    [0m | [36msgg_benchmark.data.build[0m:[36mget_dataset_statistics[0m:[36m43[0m - [1m----------------------------------------------------------------------------------------------------[0m
loading word vectors fromloading word vectors from  /gpfswork/rech/gtb/ukj95zg/glove/glove.6B.200d.pt/gpfswork/rech/gtb/ukj95zg/glove/glove.6B.200d.pt

__background__ -> __background__ __background__ -> __background__ 

fail on __background__fail on __background__

loading word vectors from /gpfswork/rech/gtb/ukj95zg/glove/glove.6B.200d.pt
loading word vectors from /gpfswork/rech/gtb/ukj95zg/glove/glove.6B.200d.pt
__background__ -> __background__ 
fail on __background__
__background__ -> __background__ 
fail on __background__
[32m2023-12-14 11:39:53.488[0m | [1mINFO    [0m | [36msgg_benchmark.utils.logger[0m:[36mlogger_step[0m:[36m15[0m - [1m#################### Step 3: Building optimizer and shcedule ####################[0m
[32m2023-12-14 11:39:53.513[0m | [1mINFO    [0m | [36msgg_benchmark.utils.checkpoint[0m:[36mload[0m:[36m64[0m - [1mLoading checkpoint from /gpfswork/rech/gtb/ukj95zg/Scene-Graph-Benchmark-Cuda11.7/checkpoints/faster_rcnn/best_model_0058000.pth[0m
[32m2023-12-14 11:39:57.117[0m | [1mINFO    [0m | [36msgg_benchmark.utils.logger[0m:[36mlogger_step[0m:[36m15[0m - [1m#################### Step 4: Building checkpointer ####################[0m
[32m2023-12-14 11:39:57.118[0m | [33m[1mWARNING [0m | [36msgg_benchmark.data.build[0m:[36mmake_data_loader[0m:[36m202[0m - [33m[1mWhen using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14[0m
[32m2023-12-14 11:42:08.037[0m | [1mINFO    [0m | [36msgg_benchmark.utils.miscellaneous[0m:[36msave_labels[0m:[36m37[0m - [1mSaving labels mapping into /gpfswork/rech/gtb/ukj95zg/Scene-Graph-Benchmark-Cuda11.7/checkpoints/VG178/labels.json[0m
[32m2023-12-14 11:42:11.280[0m | [1mINFO    [0m | [36msgg_benchmark.utils.logger[0m:[36mlogger_step[0m:[36m15[0m - [1m#################### Step 5: Building dataloader ####################[0m
[32m2023-12-14 11:42:11.280[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m138[0m - [1mStart training[0m
[32m2023-12-14 11:43:50.022[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m198[0m - [1meta: 13:41:11  iter: 100  loss: 2.4142 (3.6382)  auxiliary_ctx: 0.2430 (0.6971)  auxiliary_frq: 0.2027 (0.2034)  auxiliary_vis: 0.2976 (0.4391)  loss_refine_obj: 1.1825 (1.8209)  loss_rel: 0.4171 (0.4777)  time: 0.8821 (0.9874)  data: 0.0159 (0.0407)  lr: 0.033384  max mem: 5220[0m
[32m2023-12-14 11:45:19.420[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m198[0m - [1meta: 13:00:46  iter: 200  loss: 1.8358 (2.8211)  auxiliary_ctx: 0.1936 (0.4550)  auxiliary_frq: 0.1929 (0.1995)  auxiliary_vis: 0.2223 (0.3383)  loss_refine_obj: 0.8750 (1.4074)  loss_rel: 0.3279 (0.4209)  time: 0.8898 (0.9407)  data: 0.0158 (0.0284)  lr: 0.054984  max mem: 5220[0m
[32m2023-12-14 11:46:48.818[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m198[0m - [1meta: 12:46:18  iter: 300  loss: 1.7700 (2.4908)  auxiliary_ctx: 0.1979 (0.3725)  auxiliary_frq: 0.1923 (0.1980)  auxiliary_vis: 0.2130 (0.3019)  loss_refine_obj: 0.8332 (1.2197)  loss_rel: 0.3116 (0.3988)  time: 0.8873 (0.9251)  data: 0.0157 (0.0242)  lr: 0.076584  max mem: 5220[0m
[32m2023-12-14 11:48:18.322[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m198[0m - [1meta: 12:38:33  iter: 400  loss: 1.7720 (2.3212)  auxiliary_ctx: 0.2137 (0.3293)  auxiliary_frq: 0.1888 (0.1974)  auxiliary_vis: 0.2397 (0.2821)  loss_refine_obj: 0.8278 (1.1271)  loss_rel: 0.3412 (0.3853)  time: 0.8928 (0.9176)  data: 0.0158 (0.0222)  lr: 0.098184  max mem: 5220[0m
[32m2023-12-14 11:49:47.609[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m198[0m - [1meta: 12:32:56  iter: 500  loss: 1.6922 (2.2243)  auxiliary_ctx: 0.1791 (0.3049)  auxiliary_frq: 0.1849 (0.1979)  auxiliary_vis: 0.2065 (0.2725)  loss_refine_obj: 0.8019 (1.0695)  loss_rel: 0.2993 (0.3794)  time: 0.8901 (0.9127)  data: 0.0157 (0.0209)  lr: 0.119784  max mem: 5220[0m
[32m2023-12-14 11:51:16.531[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m198[0m - [1meta: 12:28:12  iter: 600  loss: 1.7769 (2.1589)  auxiliary_ctx: 0.2029 (0.2879)  auxiliary_frq: 0.1959 (0.1980)  auxiliary_vis: 0.2239 (0.2655)  loss_refine_obj: 0.8269 (1.0322)  loss_rel: 0.3652 (0.3752)  time: 0.8853 (0.9087)  data: 0.0158 (0.0201)  lr: 0.120000  max mem: 5220[0m
[32m2023-12-14 11:52:45.806[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m198[0m - [1meta: 12:24:48  iter: 700  loss: 1.6862 (2.0921)  auxiliary_ctx: 0.1745 (0.2730)  auxiliary_frq: 0.1886 (0.1970)  auxiliary_vis: 0.2195 (0.2570)  loss_refine_obj: 0.7657 (0.9985)  loss_rel: 0.2892 (0.3666)  time: 0.8895 (0.9065)  data: 0.0157 (0.0195)  lr: 0.120000  max mem: 5220[0m
[32m2023-12-14 11:54:15.266[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m198[0m - [1meta: 12:22:05  iter: 800  loss: 1.6214 (2.0456)  auxiliary_ctx: 0.1596 (0.2623)  auxiliary_frq: 0.1755 (0.1969)  auxiliary_vis: 0.1774 (0.2512)  loss_refine_obj: 0.7853 (0.9728)  loss_rel: 0.2937 (0.3623)  time: 0.8914 (0.9050)  data: 0.0157 (0.0190)  lr: 0.120000  max mem: 5220[0m
[32m2023-12-14 11:55:44.682[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m198[0m - [1meta: 12:19:35  iter: 900  loss: 1.5574 (2.0061)  auxiliary_ctx: 0.1660 (0.2541)  auxiliary_frq: 0.1828 (0.1967)  auxiliary_vis: 0.1798 (0.2469)  loss_refine_obj: 0.7088 (0.9493)  loss_rel: 0.2981 (0.3590)  time: 0.8953 (0.9038)  data: 0.0160 (0.0187)  lr: 0.120000  max mem: 5220[0m
[32m2023-12-14 11:57:14.098[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m198[0m - [1meta: 12:17:18  iter: 1000  loss: 1.6754 (1.9744)  auxiliary_ctx: 0.1965 (0.2478)  auxiliary_frq: 0.1985 (0.1969)  auxiliary_vis: 0.2088 (0.2436)  loss_refine_obj: 0.7574 (0.9296)  loss_rel: 0.3153 (0.3565)  time: 0.8895 (0.9028)  data: 0.0156 (0.0184)  lr: 0.120000  max mem: 5220[0m
[32m2023-12-14 11:58:43.517[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m198[0m - [1meta: 12:15:09  iter: 1100  loss: 1.6730 (1.9468)  auxiliary_ctx: 0.1795 (0.2421)  auxiliary_frq: 0.1979 (0.1971)  auxiliary_vis: 0.2011 (0.2406)  loss_refine_obj: 0.7413 (0.9135)  loss_rel: 0.3113 (0.3536)  time: 0.8902 (0.9020)  data: 0.0156 (0.0182)  lr: 0.120000  max mem: 5220[0m
[32m2023-12-14 12:00:12.873[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m198[0m - [1meta: 12:13:04  iter: 1200  loss: 1.6656 (1.9258)  auxiliary_ctx: 0.1790 (0.2379)  auxiliary_frq: 0.1887 (0.1975)  auxiliary_vis: 0.2115 (0.2389)  loss_refine_obj: 0.7554 (0.8991)  loss_rel: 0.3088 (0.3524)  time: 0.8849 (0.9013)  data: 0.0158 (0.0180)  lr: 0.120000  max mem: 5220[0m
[32m2023-12-14 12:01:42.022[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m198[0m - [1meta: 12:10:57  iter: 1300  loss: 1.6432 (1.9029)  auxiliary_ctx: 0.1893 (0.2336)  auxiliary_frq: 0.2033 (0.1973)  auxiliary_vis: 0.2114 (0.2364)  loss_refine_obj: 0.7064 (0.8854)  loss_rel: 0.3408 (0.3501)  time: 0.8834 (0.9006)  data: 0.0158 (0.0179)  lr: 0.120000  max mem: 5220[0m
[32m2023-12-14 12:03:11.332[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m198[0m - [1meta: 12:09:01  iter: 1400  loss: 1.5588 (1.8815)  auxiliary_ctx: 0.1689 (0.2296)  auxiliary_frq: 0.1901 (0.1970)  auxiliary_vis: 0.1886 (0.2336)  loss_refine_obj: 0.7434 (0.8743)  loss_rel: 0.2619 (0.3471)  time: 0.8994 (0.9000)  data: 0.0157 (0.0177)  lr: 0.120000  max mem: 5220[0m
[32m2023-12-14 12:04:40.833[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m198[0m - [1meta: 12:07:15  iter: 1500  loss: 1.5231 (1.8638)  auxiliary_ctx: 0.1645 (0.2262)  auxiliary_frq: 0.1897 (0.1970)  auxiliary_vis: 0.1870 (0.2317)  loss_refine_obj: 0.7234 (0.8642)  loss_rel: 0.2801 (0.3448)  time: 0.8889 (0.8997)  data: 0.0158 (0.0176)  lr: 0.120000  max mem: 5220[0m
[32m2023-12-14 12:06:10.250[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m198[0m - [1meta: 12:05:28  iter: 1600  loss: 1.5994 (1.8459)  auxiliary_ctx: 0.1729 (0.2226)  auxiliary_frq: 0.1937 (0.1966)  auxiliary_vis: 0.1973 (0.2294)  loss_refine_obj: 0.6831 (0.8555)  loss_rel: 0.3204 (0.3418)  time: 0.8828 (0.8994)  data: 0.0158 (0.0175)  lr: 0.120000  max mem: 5220[0m
[32m2023-12-14 12:07:39.732[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m198[0m - [1meta: 12:03:45  iter: 1700  loss: 1.5264 (1.8339)  auxiliary_ctx: 0.1702 (0.2205)  auxiliary_frq: 0.1849 (0.1969)  auxiliary_vis: 0.1855 (0.2283)  loss_refine_obj: 0.7109 (0.8471)  loss_rel: 0.2687 (0.3411)  time: 0.8918 (0.8991)  data: 0.0158 (0.0174)  lr: 0.120000  max mem: 5220[0m
[32m2023-12-14 12:09:08.908[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m198[0m - [1meta: 12:01:56  iter: 1800  loss: 1.6602 (1.8194)  auxiliary_ctx: 0.1870 (0.2180)  auxiliary_frq: 0.1994 (0.1968)  auxiliary_vis: 0.2218 (0.2267)  loss_refine_obj: 0.7012 (0.8388)  loss_rel: 0.3417 (0.3391)  time: 0.8883 (0.8987)  data: 0.0157 (0.0173)  lr: 0.120000  max mem: 5220[0m
[32m2023-12-14 12:10:38.294[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m198[0m - [1meta: 12:00:14  iter: 1900  loss: 1.5659 (1.8069)  auxiliary_ctx: 0.1660 (0.2156)  auxiliary_frq: 0.1900 (0.1965)  auxiliary_vis: 0.1875 (0.2250)  loss_refine_obj: 0.7032 (0.8327)  loss_rel: 0.2786 (0.3371)  time: 0.8919 (0.8984)  data: 0.0159 (0.0173)  lr: 0.120000  max mem: 5220[0m
[32m2023-12-14 12:12:07.472[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m198[0m - [1meta: 11:58:28  iter: 2000  loss: 1.6253 (1.7948)  auxiliary_ctx: 0.1722 (0.2134)  auxiliary_frq: 0.1958 (0.1963)  auxiliary_vis: 0.1961 (0.2235)  loss_refine_obj: 0.7195 (0.8263)  loss_rel: 0.3003 (0.3353)  time: 0.8891 (0.8981)  data: 0.0158 (0.0172)  lr: 0.120000  max mem: 5220[0m
[32m2023-12-14 12:12:07.473[0m | [1mINFO    [0m | [36m__main__[0m:[36mtrain[0m:[36m224[0m - [1mStart validating[0m
[32m2023-12-14 12:12:07.527[0m | [1mINFO    [0m | [36msgg_benchmark.engine.inference[0m:[36minference[0m:[36m150[0m - [1mStart evaluation on VG178_val dataset(5000 images).[0m
[32m2023-12-14 12:26:20.834[0m | [1mINFO    [0m | [36msgg_benchmark.engine.inference[0m:[36minference[0m:[36m166[0m - [1mTotal run time: 0:14:13.306377 (0.3413225509643555 s / img per device, on 2 devices)[0m
[32m2023-12-14 12:26:20.862[0m | [1mINFO    [0m | [36msgg_benchmark.engine.inference[0m:[36minference[0m:[36m172[0m - [1mModel inference time: 0:13:44.283229 (0.32971329174041747 s / img per device, on 2 devices)[0m
creating index...
index created!
Loading and preparing results...
Converting ndarray to lists...
(250000, 7)
0/250000
DONE (t=2.15s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=39.16s).
Accumulating evaluation results...
DONE (t=11.57s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.093
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.201
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.075
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.034
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.058
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.128
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.216
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.218
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.158
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.260
[32m2023-12-14 12:29:06.222[0m | [1mINFO    [0m | [36msgg_benchmark.data.datasets.evaluation.vg.vg_eval[0m:[36mdo_vg_evaluation[0m:[36m189[0m - [1m
====================================================================================================
Detection evaluation mAp=0.2013
====================================================================================================
SGG eval:     R @ 20: 0.0574;     R @ 50: 0.0804;     R @ 100: 0.1025;  for mode=sgdet, type=Recall(Main).
SGG eval:  ng-R @ 20: 0.0649;  ng-R @ 50: 0.1012;  ng-R @ 100: 0.1341;  for mode=sgdet, type=No Graph Constraint Recall(Main).
SGG eval:    zR @ 20: 0.0000;    zR @ 50: 0.0000;    zR @ 100: 0.0000;  for mode=sgdet, type=Zero Shot Recall.
SGG eval: ng-zR @ 20: 0.0000; ng-zR @ 50: 0.0000; ng-zR @ 100: 0.0645;  for mode=sgdet, type=No Graph Constraint Zero Shot Recall.
SGG eval:    mR @ 20: 0.0399;    mR @ 50: 0.0589;    mR @ 100: 0.0740;  for mode=sgdet, type=Mean Recall.
----------------------- Details ------------------------
(on:0.0489) (next to:0.0211) (has:0.3026) (parked on:0.0544) (by:0.0000) (with:0.0047) (along:0.0000) (against:0.0000) (in:0.0541) (under:0.0497) (of:0.1395) (wearing:0.4741) (sitting in:0.0000) (wears:0.0000) (beside:0.0034) (walking on:0.1624) (at:0.0000) (on top of:0.1035) (behind:0.1787) (made of:0.0000) (have:0.0000) (near:0.0501) (sitting on:0.0286) (hanging on:0.4861) (in front of:0.1274) (carrying:0.0000) (above:0.2325) (over:0.0000) (and:0.0000) (on side of:0.0215) (riding:0.4512) (inside:0.0000) (attached to:0.0000) (around:0.0000) (holding:0.0950) (standing on:0.0127) (laying on:0.0000) (for:0.0000) (below:0.0000) (standing in:0.1243) (covering:0.0000) (covered in:0.0000) (belonging to:0.0000) (eating:0.0000) (looking at:0.1053) 
--------------------------------------------------------
SGG eval: ng-mR @ 20: 0.0433; ng-mR @ 50: 0.0651; ng-mR @ 100: 0.0953;  for mode=sgdet, type=No Graph Constraint Mean Recall.
----------------------- Details ------------------------
(on:0.1022) (next to:0.0711) (has:0.2762) (parked on:0.0257) (by:0.0262) (with:0.0693) (along:0.0000) (against:0.0397) (in:0.0475) (under:0.0497) (of:0.1377) (wearing:0.4662) (sitting in:0.0000) (wears:0.2652) (beside:0.0274) (walking on:0.1432) (at:0.0000) (on top of:0.1279) (behind:0.1654) (made of:0.0000) (have:0.0000) (near:0.0831) (sitting on:0.0873) (hanging on:0.4224) (in front of:0.1238) (carrying:0.0484) (above:0.2354) (over:0.0962) (and:0.0000) (on side of:0.0305) (riding:0.4024) (inside:0.0000) (attached to:0.0000) (around:0.0000) (holding:0.0883) (standing on:0.0380) (laying on:0.0417) (for:0.0000) (below:0.0250) (standing in:0.1757) (covering:0.0000) (covered in:0.0000) (belonging to:0.0636) (eating:0.0769) (looking at:0.2105) 
--------------------------------------------------------
====================================================================================================
[0m
