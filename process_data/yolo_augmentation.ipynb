{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/home/maelic/Documents/PhD/MyModel/PhD_Commonsense_Enrichment/VG_refinement/data_tools/IndoorVG_3/YOLO_anno\"\n",
    "yaml_path = \"/home/maelic/Documents/PhD/MyModel/PhD_Commonsense_Enrichment/VG_refinement/data_tools/IndoorVG_3/YOLO_anno/IndoorVG3.yaml\"\n",
    "\n",
    "model_path = \"/home/maelic/Documents/PhD/MyModel/Scene-Graph-Benchmark-Cuda11.7/datasets/IndoorVG/yolov8l_indoorvg.pt\"\n",
    "\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# load model\n",
    "model = YOLO(model_path)\n",
    "\n",
    "from ultralytics.cfg import get_cfg\n",
    "\n",
    "cfg = get_cfg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/maelic/Documents/PhD/MyModel/PhD_Commonsense_Enrichment/VG_refinement/data_tools/IndoorVG_3/YOLO_anno/val/labels.cache... 9847 images, 0 backgrounds, 0 corrupt: 100%|██████████| 9847/9847 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/maelic/Documents/PhD/MyModel/PhD_Commonsense_Enrichment/VG_refinement/data_tools/IndoorVG_3/YOLO_anno/val/images/1592276.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /home/maelic/Documents/PhD/MyModel/PhD_Commonsense_Enrichment/VG_refinement/data_tools/IndoorVG_3/YOLO_anno/val/images/2560.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "<ultralytics.data.dataset.YOLODataset object at 0x7f788dd07790>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load train data\n",
    "# load yaml\n",
    "from ultralytics.utils import yaml_load\n",
    "from ultralytics.data import build_dataloader, build_yolo_dataset\n",
    "\n",
    "data = yaml_load(yaml_path)\n",
    "\n",
    "# loda dataset\n",
    "from ultralytics.data import YOLODataset\n",
    "\n",
    "# load dataset\n",
    "splits = [data['train'], data['val'], data['test']]\n",
    "\n",
    "split = splits[1]\n",
    "img_dir = os.path.join(split, 'images')\n",
    "dataset = build_yolo_dataset(cfg, img_dir, 1, data)\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset_path = \"/home/maelic/Documents/PhD/MyModel/PhD_Commonsense_Enrichment/VG_refinement/data_tools/IndoorVG_3/YOLO_anno_v2\"\n",
    "# create dir\n",
    "os.makedirs(new_dataset_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/maelic/Documents/PhD/MyModel/PhD_Commonsense_Enrichment/VG_refinement/data_tools/IndoorVG_3/YOLO_anno/val/images/1001.jpg: 480x640 (no detections), 19.8ms\n",
      "Speed: 2.4ms preprocess, 19.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "1\n",
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([], device='cuda:0')\n",
      "conf: tensor([], device='cuda:0')\n",
      "data: tensor([], device='cuda:0', size=(0, 6))\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (600, 800)\n",
      "shape: torch.Size([0, 6])\n",
      "xywh: tensor([], device='cuda:0', size=(0, 4))\n",
      "xywhn: tensor([], device='cuda:0', size=(0, 4))\n",
      "xyxy: tensor([], device='cuda:0', size=(0, 4))\n",
      "xyxyn: tensor([], device='cuda:0', size=(0, 4))\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "from utils import bbox_iou\n",
    "\n",
    "iou_thres = 0.5\n",
    "conf_thres = 0.5\n",
    "\n",
    "# img_file = \"/home/maelic/Documents/PhD/MyModel/PhD_Commonsense_Enrichment/VG_refinement/data_tools/IndoorVG_3/YOLO_anno/val/images/12.jpg\"\n",
    "\n",
    "# run model on dataset\n",
    "for img in dataset:\n",
    "    # get gt boxes\n",
    "    gt_boxes = img['bboxes'].cuda()\n",
    "\n",
    "    # forward pass\n",
    "    results = model(img['im_file'])\n",
    "\n",
    "    print(len(results))\n",
    "\n",
    "    print(results[0].boxes)\n",
    "    print(gt_boxes.shape)\n",
    "\n",
    "    # iou on gt boxes and predictions\n",
    "    for i, box in enumerate(results[0].boxes.xywh):\n",
    "        iou = bbox_iou(box, gt_boxes, xywh=True)\n",
    "        print(iou)\n",
    "        if iou < iou_thres:\n",
    "            # the box is a candidate for a new object\n",
    "            if box.conf[i] > conf_thres:\n",
    "                # save the box\n",
    "                pass\n",
    "    \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
